sth happened bad


"C:\Program Files\Anaconda2\python.exe" D:/Projects/VCOM/opencv-learning-python-project/deep-learning/cifar10_custom.py
Using Theano backend.
Using gpu device 0: GeForce GTX 860M (CNMeM is enabled with initial size: 82.5% of memory, cuDNN 5005)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 32, 32)    896         convolution2d_input_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 32, 32)    0           convolution2d_1[0][0]
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 32, 32)    9248        dropout_1[0][0]
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 32, 16, 16)    0           convolution2d_2[0][0]
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 16, 16)    18496       maxpooling2d_1[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 16, 16)    0           convolution2d_3[0][0]
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 64, 16, 16)    36928       dropout_2[0][0]
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 8, 8)      0           convolution2d_4[0][0]
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 128, 8, 8)     73856       maxpooling2d_2[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 8, 8)     0           convolution2d_5[0][0]
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 128, 8, 8)     147584      dropout_3[0][0]
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 4, 4)     0           convolution2d_6[0][0]
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 256, 4, 4)     295168      maxpooling2d_3[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 4, 4)     0           convolution2d_7[0][0]
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 256, 4, 4)     590080      dropout_4[0][0]
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 2, 2)     0           convolution2d_8[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           maxpooling2d_4[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 1024)          0           flatten_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          1049600     dropout_5[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 512)           524800      dropout_6[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 512)           0           dense_2[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 10L)           5130        dropout_7[0][0]
====================================================================================================
Total params: 2751786
____________________________________________________________________________________________________
None
Epoch 1/50
169s - loss: 2.3214 - acc: 0.1072 - val_loss: 2.2953 - val_acc: 0.1297
Epoch 2/50
167s - loss: 2.0715 - acc: 0.2127 - val_loss: 2.2731 - val_acc: 0.1795
Epoch 3/50
168s - loss: 1.8206 - acc: 0.3125 - val_loss: 1.8042 - val_acc: 0.3372
Epoch 4/50
166s - loss: 1.7095 - acc: 0.3692 - val_loss: 1.7564 - val_acc: 0.3681
Epoch 5/50
166s - loss: 1.6364 - acc: 0.3976 - val_loss: 1.7810 - val_acc: 0.3760
Epoch 6/50
165s - loss: 1.5784 - acc: 0.4204 - val_loss: 1.4946 - val_acc: 0.4583
Epoch 7/50
167s - loss: 1.5331 - acc: 0.4406 - val_loss: 1.6404 - val_acc: 0.4230
Epoch 8/50
163s - loss: 1.4932 - acc: 0.4558 - val_loss: 1.3980 - val_acc: 0.5024
Epoch 9/50
165s - loss: 1.4492 - acc: 0.4758 - val_loss: 1.3778 - val_acc: 0.5161
Epoch 10/50
165s - loss: 1.4208 - acc: 0.4880 - val_loss: 1.3639 - val_acc: 0.5102
Epoch 11/50
168s - loss: 1.3837 - acc: 0.5024 - val_loss: 1.3968 - val_acc: 0.5132
Epoch 12/50
142s - loss: 1.3522 - acc: 0.5173 - val_loss: 1.4047 - val_acc: 0.5259
Epoch 13/50
168s - loss: 1.3203 - acc: 0.5279 - val_loss: 1.2702 - val_acc: 0.5593
Epoch 14/50
165s - loss: 1.2935 - acc: 0.5389 - val_loss: 1.2019 - val_acc: 0.5971
Epoch 15/50
166s - loss: 1.2648 - acc: 0.5501 - val_loss: 1.2006 - val_acc: 0.5875
Epoch 16/50
167s - loss: 1.2457 - acc: 0.5555 - val_loss: 1.2040 - val_acc: 0.5829
Epoch 17/50
166s - loss: 1.2142 - acc: 0.5703 - val_loss: 1.2474 - val_acc: 0.5752
Epoch 18/50
165s - loss: 1.2081 - acc: 0.5740 - val_loss: 1.1607 - val_acc: 0.6136
Epoch 19/50
168s - loss: 1.1798 - acc: 0.5860 - val_loss: 1.0662 - val_acc: 0.6297
Epoch 20/50
166s - loss: 1.1569 - acc: 0.5960 - val_loss: 1.0467 - val_acc: 0.6436
Epoch 21/50
165s - loss: 1.1433 - acc: 0.5997 - val_loss: 1.0681 - val_acc: 0.6500
Epoch 22/50
166s - loss: 1.1336 - acc: 0.6046 - val_loss: 1.0345 - val_acc: 0.6535
Epoch 23/50
167s - loss: 1.1099 - acc: 0.6111 - val_loss: 1.0010 - val_acc: 0.6751
Epoch 24/50
165s - loss: 1.1003 - acc: 0.6163 - val_loss: 1.0754 - val_acc: 0.6451
Epoch 25/50
168s - loss: 1.0811 - acc: 0.6232 - val_loss: 1.0090 - val_acc: 0.6744
Epoch 26/50
165s - loss: 1.0777 - acc: 0.6252 - val_loss: 1.0230 - val_acc: 0.6598
Epoch 27/50
168s - loss: 1.0631 - acc: 0.6286 - val_loss: 0.9937 - val_acc: 0.6809
Epoch 28/50
168s - loss: 1.0528 - acc: 0.6334 - val_loss: 0.9112 - val_acc: 0.7058
Epoch 29/50
166s - loss: 1.0366 - acc: 0.6403 - val_loss: 0.9566 - val_acc: 0.6848
Epoch 30/50
165s - loss: 1.0335 - acc: 0.6392 - val_loss: 0.9074 - val_acc: 0.7113
Epoch 31/50
167s - loss: 1.0148 - acc: 0.6486 - val_loss: 1.0462 - val_acc: 0.6599
Epoch 32/50
167s - loss: 1.0132 - acc: 0.6480 - val_loss: 0.9568 - val_acc: 0.6823
Epoch 33/50
166s - loss: 1.0004 - acc: 0.6542 - val_loss: 0.9614 - val_acc: 0.6845
Epoch 34/50
167s - loss: 0.9901 - acc: 0.6564 - val_loss: 0.8891 - val_acc: 0.7081
Epoch 35/50
168s - loss: 0.9822 - acc: 0.6614 - val_loss: 0.9157 - val_acc: 0.7025
Epoch 36/50
166s - loss: 0.9756 - acc: 0.6645 - val_loss: 0.8743 - val_acc: 0.7076
Epoch 37/50
168s - loss: 0.9654 - acc: 0.6663 - val_loss: 0.8763 - val_acc: 0.7091
Epoch 38/50
168s - loss: 0.9653 - acc: 0.6677 - val_loss: 0.8393 - val_acc: 0.7291
Epoch 39/50
166s - loss: 0.9458 - acc: 0.6712 - val_loss: 0.8672 - val_acc: 0.7264
Epoch 40/50
166s - loss: 0.9409 - acc: 0.6731 - val_loss: 0.9026 - val_acc: 0.7136
Epoch 41/50
167s - loss: 0.9376 - acc: 0.6753 - val_loss: 0.8169 - val_acc: 0.7353
Epoch 42/50
165s - loss: 0.9265 - acc: 0.6818 - val_loss: 0.8514 - val_acc: 0.7245
Epoch 43/50
168s - loss: 0.9188 - acc: 0.6838 - val_loss: 0.7758 - val_acc: 0.7513
Epoch 44/50
167s - loss: 0.9127 - acc: 0.6831 - val_loss: 0.8069 - val_acc: 0.7398
Epoch 45/50
167s - loss: 0.9064 - acc: 0.6866 - val_loss: 0.8263 - val_acc: 0.7412
Epoch 46/50
165s - loss: 0.8993 - acc: 0.6908 - val_loss: 0.8893 - val_acc: 0.7026
Epoch 47/50
167s - loss: 0.8920 - acc: 0.6929 - val_loss: 0.8128 - val_acc: 0.7315
Epoch 48/50
166s - loss: 0.8857 - acc: 0.6940 - val_loss: 0.8030 - val_acc: 0.7414
Epoch 49/50

Process finished with exit code 1


