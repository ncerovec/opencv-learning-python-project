"C:\Program Files\Anaconda2\python.exe" D:/Projects/VCOM/opencv-learning-python-project/deep-learning/cifar10_custom.py
Using Theano backend.
Using gpu device 0: GeForce GTX 860M (CNMeM is enabled with initial size: 82.5% of memory, cuDNN 5005)
Model visualisation saved to custom.png
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 32, 32)    896         convolution2d_input_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 32, 32)    0           convolution2d_1[0][0]
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 32, 32)    9248        dropout_1[0][0]
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 32, 16, 16)    0           convolution2d_2[0][0]
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 16, 16)    18496       maxpooling2d_1[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 16, 16)    0           convolution2d_3[0][0]
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 64, 16, 16)    36928       dropout_2[0][0]
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 8, 8)      0           convolution2d_4[0][0]
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 128, 8, 8)     73856       maxpooling2d_2[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 8, 8)     0           convolution2d_5[0][0]
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 128, 8, 8)     147584      dropout_3[0][0]
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 4, 4)     0           convolution2d_6[0][0]
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 256, 4, 4)     295168      maxpooling2d_3[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 4, 4)     0           convolution2d_7[0][0]
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 256, 4, 4)     590080      dropout_4[0][0]
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 2, 2)     0           convolution2d_8[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           maxpooling2d_4[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 1024)          0           flatten_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          1049600     dropout_5[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 512)           524800      dropout_6[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 512)           0           dense_2[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 10L)           5130        dropout_7[0][0]
====================================================================================================
Total params: 2751786
____________________________________________________________________________________________________
None
Epoch 1/100
52s - loss: 2.0682 - acc: 0.2302 - val_loss: 1.7954 - val_acc: 0.3304
Epoch 2/100
52s - loss: 1.7184 - acc: 0.3700 - val_loss: 1.5179 - val_acc: 0.4356
Epoch 3/100
52s - loss: 1.5063 - acc: 0.4525 - val_loss: 1.3703 - val_acc: 0.4966
Epoch 4/100
52s - loss: 1.3536 - acc: 0.5132 - val_loss: 1.2445 - val_acc: 0.5610
Epoch 5/100
52s - loss: 1.2321 - acc: 0.5600 - val_loss: 1.1652 - val_acc: 0.5920
Epoch 6/100
52s - loss: 1.1262 - acc: 0.6014 - val_loss: 1.1882 - val_acc: 0.5935
Epoch 7/100
52s - loss: 1.0457 - acc: 0.6329 - val_loss: 1.0281 - val_acc: 0.6375
Epoch 8/100
52s - loss: 0.9727 - acc: 0.6575 - val_loss: 0.8559 - val_acc: 0.6999
Epoch 9/100
52s - loss: 0.9247 - acc: 0.6789 - val_loss: 0.7938 - val_acc: 0.7224
Epoch 10/100
52s - loss: 0.8706 - acc: 0.6960 - val_loss: 0.7594 - val_acc: 0.7371
Epoch 11/100
52s - loss: 0.8340 - acc: 0.7106 - val_loss: 0.8160 - val_acc: 0.7257
Epoch 12/100
52s - loss: 0.7943 - acc: 0.7255 - val_loss: 0.7099 - val_acc: 0.7576
Epoch 13/100
52s - loss: 0.7708 - acc: 0.7337 - val_loss: 0.7314 - val_acc: 0.7466
Epoch 14/100
52s - loss: 0.7450 - acc: 0.7425 - val_loss: 0.6566 - val_acc: 0.7788
Epoch 15/100
52s - loss: 0.7276 - acc: 0.7478 - val_loss: 0.6376 - val_acc: 0.7840
Epoch 16/100
52s - loss: 0.7034 - acc: 0.7560 - val_loss: 0.6455 - val_acc: 0.7783
Epoch 17/100
52s - loss: 0.6862 - acc: 0.7613 - val_loss: 0.6728 - val_acc: 0.7803
Epoch 18/100
52s - loss: 0.6692 - acc: 0.7674 - val_loss: 0.5661 - val_acc: 0.8106
Epoch 19/100
52s - loss: 0.6512 - acc: 0.7726 - val_loss: 0.7256 - val_acc: 0.7550
Epoch 20/100
52s - loss: 0.6388 - acc: 0.7803 - val_loss: 0.5632 - val_acc: 0.8119
Epoch 21/100
52s - loss: 0.6247 - acc: 0.7856 - val_loss: 0.5819 - val_acc: 0.8099
Epoch 22/100
52s - loss: 0.6125 - acc: 0.7893 - val_loss: 0.5429 - val_acc: 0.8185
Epoch 23/100
52s - loss: 0.6034 - acc: 0.7907 - val_loss: 0.5400 - val_acc: 0.8178
Epoch 24/100
52s - loss: 0.5933 - acc: 0.7978 - val_loss: 0.5494 - val_acc: 0.8167
Epoch 25/100
52s - loss: 0.5798 - acc: 0.8023 - val_loss: 0.5817 - val_acc: 0.8003
Epoch 26/100
52s - loss: 0.5729 - acc: 0.8032 - val_loss: 0.5657 - val_acc: 0.8107
Epoch 27/100
52s - loss: 0.5665 - acc: 0.8042 - val_loss: 0.5443 - val_acc: 0.8243
Epoch 28/100
52s - loss: 0.5554 - acc: 0.8098 - val_loss: 0.5386 - val_acc: 0.8216
Epoch 29/100
52s - loss: 0.5477 - acc: 0.8123 - val_loss: 0.5183 - val_acc: 0.8287
Epoch 30/100
52s - loss: 0.5479 - acc: 0.8122 - val_loss: 0.5031 - val_acc: 0.8314
Epoch 31/100
52s - loss: 0.5391 - acc: 0.8172 - val_loss: 0.5493 - val_acc: 0.8186
Epoch 32/100
52s - loss: 0.5295 - acc: 0.8197 - val_loss: 0.5054 - val_acc: 0.8324
Epoch 33/100
52s - loss: 0.5218 - acc: 0.8198 - val_loss: 0.6367 - val_acc: 0.7891
Epoch 34/100
52s - loss: 0.5216 - acc: 0.8211 - val_loss: 0.4710 - val_acc: 0.8435
Epoch 35/100
52s - loss: 0.5196 - acc: 0.8225 - val_loss: 0.4950 - val_acc: 0.8327
Epoch 36/100
52s - loss: 0.5110 - acc: 0.8249 - val_loss: 0.4648 - val_acc: 0.8471
Epoch 37/100
52s - loss: 0.5046 - acc: 0.8282 - val_loss: 0.5155 - val_acc: 0.8287
Epoch 38/100
52s - loss: 0.4942 - acc: 0.8291 - val_loss: 0.4869 - val_acc: 0.8422
Epoch 39/100
52s - loss: 0.4939 - acc: 0.8305 - val_loss: 0.4786 - val_acc: 0.8439
Epoch 40/100
52s - loss: 0.4889 - acc: 0.8318 - val_loss: 0.4944 - val_acc: 0.8384
Epoch 41/100
52s - loss: 0.4845 - acc: 0.8338 - val_loss: 0.4946 - val_acc: 0.8364
Epoch 42/100
52s - loss: 0.4803 - acc: 0.8361 - val_loss: 0.6337 - val_acc: 0.7873
Epoch 43/100
52s - loss: 0.4850 - acc: 0.8357 - val_loss: 0.4828 - val_acc: 0.8379
Epoch 44/100
52s - loss: 0.4736 - acc: 0.8393 - val_loss: 0.4660 - val_acc: 0.8441
Epoch 45/100
52s - loss: 0.4717 - acc: 0.8386 - val_loss: 0.4405 - val_acc: 0.8559
Epoch 46/100
52s - loss: 0.4656 - acc: 0.8427 - val_loss: 0.4544 - val_acc: 0.8504
Epoch 47/100
52s - loss: 0.4627 - acc: 0.8422 - val_loss: 0.5008 - val_acc: 0.8342
Epoch 48/100
52s - loss: 0.4585 - acc: 0.8433 - val_loss: 0.4804 - val_acc: 0.8446
Epoch 49/100
52s - loss: 0.4574 - acc: 0.8442 - val_loss: 0.4457 - val_acc: 0.8574
Epoch 50/100
52s - loss: 0.4512 - acc: 0.8456 - val_loss: 0.5073 - val_acc: 0.8430
Epoch 51/100
52s - loss: 0.4519 - acc: 0.8465 - val_loss: 0.4645 - val_acc: 0.8525
Epoch 52/100
52s - loss: 0.4493 - acc: 0.8460 - val_loss: 0.4681 - val_acc: 0.8502
Epoch 53/100
52s - loss: 0.4525 - acc: 0.8466 - val_loss: 0.4299 - val_acc: 0.8576
Epoch 54/100
52s - loss: 0.4444 - acc: 0.8477 - val_loss: 0.4703 - val_acc: 0.8451
Epoch 55/100
52s - loss: 0.4376 - acc: 0.8507 - val_loss: 0.4563 - val_acc: 0.8537
Epoch 56/100
52s - loss: 0.4427 - acc: 0.8485 - val_loss: 0.4478 - val_acc: 0.8554
Epoch 57/100
52s - loss: 0.4340 - acc: 0.8515 - val_loss: 0.4526 - val_acc: 0.8544
Epoch 58/100
52s - loss: 0.4311 - acc: 0.8527 - val_loss: 0.4524 - val_acc: 0.8527
Epoch 59/100
52s - loss: 0.4340 - acc: 0.8525 - val_loss: 0.4327 - val_acc: 0.8597
Epoch 60/100
52s - loss: 0.4272 - acc: 0.8557 - val_loss: 0.4463 - val_acc: 0.8529
Epoch 61/100
52s - loss: 0.4314 - acc: 0.8535 - val_loss: 0.4466 - val_acc: 0.8604
Epoch 62/100
52s - loss: 0.4197 - acc: 0.8566 - val_loss: 0.4324 - val_acc: 0.8580
Epoch 63/100
52s - loss: 0.4286 - acc: 0.8567 - val_loss: 0.4332 - val_acc: 0.8653
Epoch 64/100
52s - loss: 0.4263 - acc: 0.8566 - val_loss: 0.4440 - val_acc: 0.8568
Epoch 65/100
52s - loss: 0.4256 - acc: 0.8566 - val_loss: 0.4542 - val_acc: 0.8548
Epoch 66/100
52s - loss: 0.4218 - acc: 0.8568 - val_loss: 0.4225 - val_acc: 0.8651
Epoch 67/100
52s - loss: 0.4178 - acc: 0.8584 - val_loss: 0.4306 - val_acc: 0.8585
Epoch 68/100
52s - loss: 0.4185 - acc: 0.8589 - val_loss: 0.4274 - val_acc: 0.8660
Epoch 69/100
52s - loss: 0.4182 - acc: 0.8589 - val_loss: 0.4352 - val_acc: 0.8633
Epoch 70/100
52s - loss: 0.4078 - acc: 0.8615 - val_loss: 0.4540 - val_acc: 0.8509
Epoch 71/100
52s - loss: 0.4059 - acc: 0.8624 - val_loss: 0.4445 - val_acc: 0.8545
Epoch 72/100
52s - loss: 0.4061 - acc: 0.8616 - val_loss: 0.4591 - val_acc: 0.8532
Epoch 73/100
52s - loss: 0.4040 - acc: 0.8632 - val_loss: 0.4465 - val_acc: 0.8570
Epoch 74/100
52s - loss: 0.4088 - acc: 0.8605 - val_loss: 0.4361 - val_acc: 0.8677
Epoch 75/100
52s - loss: 0.4064 - acc: 0.8619 - val_loss: 0.4703 - val_acc: 0.8508
Epoch 76/100
52s - loss: 0.4001 - acc: 0.8642 - val_loss: 0.4052 - val_acc: 0.8692
Epoch 77/100
52s - loss: 0.4007 - acc: 0.8640 - val_loss: 0.4485 - val_acc: 0.8606
Epoch 78/100
52s - loss: 0.4038 - acc: 0.8644 - val_loss: 0.4120 - val_acc: 0.8664
Epoch 79/100
52s - loss: 0.3968 - acc: 0.8664 - val_loss: 0.4394 - val_acc: 0.8589
Epoch 80/100
52s - loss: 0.4017 - acc: 0.8645 - val_loss: 0.4488 - val_acc: 0.8533
Epoch 81/100
52s - loss: 0.4016 - acc: 0.8658 - val_loss: 0.4503 - val_acc: 0.8571
Epoch 82/100
52s - loss: 0.3952 - acc: 0.8689 - val_loss: 0.4620 - val_acc: 0.8543
Epoch 83/100
52s - loss: 0.4060 - acc: 0.8640 - val_loss: 0.4128 - val_acc: 0.8699
Epoch 84/100
52s - loss: 0.3968 - acc: 0.8668 - val_loss: 0.4689 - val_acc: 0.8427
Epoch 85/100
52s - loss: 0.4019 - acc: 0.8653 - val_loss: 0.4242 - val_acc: 0.8708
Epoch 86/100
52s - loss: 0.3970 - acc: 0.8673 - val_loss: 0.4359 - val_acc: 0.8625
Epoch 87/100
52s - loss: 0.3936 - acc: 0.8657 - val_loss: 0.4930 - val_acc: 0.8449
Epoch 88/100
52s - loss: 0.3978 - acc: 0.8675 - val_loss: 0.4558 - val_acc: 0.8541
Epoch 89/100
52s - loss: 0.3949 - acc: 0.8681 - val_loss: 0.4713 - val_acc: 0.8470
Epoch 90/100
52s - loss: 0.3972 - acc: 0.8676 - val_loss: 0.4091 - val_acc: 0.8656
Epoch 91/100
52s - loss: 0.3976 - acc: 0.8667 - val_loss: 0.4394 - val_acc: 0.8615
Epoch 92/100
52s - loss: 0.3962 - acc: 0.8689 - val_loss: 0.4071 - val_acc: 0.8700
Epoch 93/100
52s - loss: 0.3901 - acc: 0.8696 - val_loss: 0.4744 - val_acc: 0.8463
Epoch 94/100
52s - loss: 0.3946 - acc: 0.8676 - val_loss: 0.4452 - val_acc: 0.8584
Epoch 95/100
52s - loss: 0.3960 - acc: 0.8677 - val_loss: 0.4111 - val_acc: 0.8716
Epoch 96/100
52s - loss: 0.3961 - acc: 0.8688 - val_loss: 0.4509 - val_acc: 0.8531
Epoch 97/100
52s - loss: 0.3918 - acc: 0.8701 - val_loss: 0.4151 - val_acc: 0.8710
Epoch 98/100
52s - loss: 0.3873 - acc: 0.8694 - val_loss: 0.4183 - val_acc: 0.8662
Epoch 99/100
52s - loss: 0.3950 - acc: 0.8674 - val_loss: 0.4061 - val_acc: 0.8678
Epoch 100/100
52s - loss: 0.4005 - acc: 0.8651 - val_loss: 0.4265 - val_acc: 0.8665
Accuracy: 86.65%

Process finished with exit code 0
